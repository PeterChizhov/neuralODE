{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pprint\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchviz\n",
    "import einops\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "    \n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'arch_hid_dim': {'values': [2, 4, 8, 16]},\n",
      "                'arch_in_dim': {'value': 2},\n",
      "                'batch_size': {'values': [16, 32, 64, 128]},\n",
      "                'dataset_type': {'value': 'hyst_saved'},\n",
      "                'epochs': {'values': [1000, 3000, 10000]},\n",
      "                'learning_rate': {'value': 0.01},\n",
      "                'optimizer': {'value': 'adam'},\n",
      "                'return_whole_sequence': {'value': False},\n",
      "                'solver_type': {'values': ['euler', 'rk4', 'dopri5', 'bosh3']},\n",
      "                'time_idependent_num_ts': {'values': [2, 5, 10, 50]}}}\n"
     ]
    }
   ],
   "source": [
    "parameters_dict = {\n",
    "    # dataset params\n",
    "    'dataset_type': {'value': 'hyst_saved'}, \n",
    "    # fixed params\n",
    "    'optimizer': {'value': 'adam'},\n",
    "    # architecture params\n",
    "    'arch_in_dim' : {'value': 2},\n",
    "    'arch_hid_dim' : {'values': [2, 4, 8, 16]},\n",
    "    # learning params\n",
    "    'epochs' : {'values': [1000, 3000, 10000]},\n",
    "    'batch_size' : {'values': [16, 32, 64, 128]},\n",
    "    'learning_rate' : {'value': 0.01},\n",
    "    # neural ODE specific params\n",
    "    'solver_type' : {'values' : ['euler', 'rk4', 'dopri5', 'bosh3']},\n",
    "    'time_idependent_num_ts' : {'values' : [2, 5, 10, 50]},\n",
    "    'return_whole_sequence' : {'value' : False},\n",
    "\n",
    "    # 'fc_layer_size': {\n",
    "    #     'values': [128, 256, 512]\n",
    "    #     },\n",
    "    # 'dropout': {\n",
    "    #       'values': [0.3, 0.4, 0.5]\n",
    "    #     },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive-step:\n",
    "- dopri8 Runge-Kutta 7(8) of Dormand-Prince-Shampine\n",
    "- dopri5 Runge-Kutta 4(5) of Dormand-Prince [default].\n",
    "- bosh3 Runge-Kutta 2(3) of Bogacki-Shampine\n",
    "- adaptive_heun Runge-Kutta 1(2)\n",
    "\n",
    "Fixed-step:\n",
    "- euler Euler method.\n",
    "- midpoint Midpoint method.\n",
    "- rk4 Fourth-order Runge-Kutta with 3/8 rule.\n",
    "- explicit_adams Explicit Adams.\n",
    "- implicit_adams Implicit Adams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.dataset_type\n",
    "from data_utils import load_existing_hyst_dataset, create_hyst_dataset\n",
    "from models import ODEFunc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.functional.mse_loss\n",
    "\n",
    "def train(project='test-neuralODE-sweep', config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        trainloader, testloader, full_X, full_y, no_noise_y = build_dataset(config.dataset_type, config.batch_size)\n",
    "        network = build_network(config.arch_in_dim, config.arch_hid_dim)\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "        print(optimizer)\n",
    "        # pred_y = odeint(func, batch_y0, batch_t, method=config.solver_type, adjoint_method=config.solver_type).to(device)\n",
    "        train_epochs(model=network,\n",
    "                      train_loader=trainloader,\n",
    "                       test_loader=testloader,\n",
    "                         criterion=criterion,\n",
    "                           optimizer=optimizer,  \n",
    "                           full_X=full_X,\n",
    "                             full_y=full_y, \n",
    "                             config=config)\n",
    "        # model, train_loader, test_loader, criterion, optimizer, full_X, full_y, config\n",
    "        # for epoch in range(config.epochs):\n",
    "        #     avg_loss = train_epoch(network, trainloader, testloader, optimizer, solver_type=config.solver_type)\n",
    "        #     wandb.log({\"loss\": avg_loss, \"epoch\": epoch})\n",
    "\n",
    "def build_dataset(which, batch_size):\n",
    "    \"\"\"\n",
    "    which: 'hyst', 'hyst_saved', 'experimental', 'experimental_saved'\n",
    "    \"\"\"\n",
    "    if which=='hyst':\n",
    "        train_dataset, test_dataset, X_full, y_full, no_noise_y  = create_hyst_dataset()\n",
    "    elif which=='hyst_saved':\n",
    "        train_dataset, test_dataset, X_full, y_full, no_noise_y = load_existing_hyst_dataset() \n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                  train_dataset, \n",
    "                  batch_size=batch_size)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                    test_dataset,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "    return trainloader, testloader, X_full, y_full, no_noise_y\n",
    "\n",
    "\n",
    "def build_network(in_dim, hid_dim):\n",
    "    network = ODEFunc(in_dim=in_dim, hid_dim=hid_dim)\n",
    "\n",
    "    return network.to(device)\n",
    "        \n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train_epoch(network, train_loader, test_loader, optimizer, config):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ➡ Forward pass\n",
    "        loss = F.nll_loss(network(data), target)\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        # ⬅ Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"batch MSE\": loss.item()})\n",
    "\n",
    "    return cumu_loss / len(train_loader) \n",
    "\n",
    "def train_epochs(model, train_loader, test_loader, criterion, optimizer, full_X, full_y, config):\n",
    "        # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    \"\"\"\n",
    "    includes:\n",
    "    learning for n epochs\n",
    "    logging train loss every epoch\n",
    "    testing on val_set every epoch\n",
    "    logging test loss every epoch\n",
    "\n",
    "    saving weights for best epoch\n",
    "    logging visualisation to wandb for best epoch\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # time to input to odeint\n",
    "    t = torch.linspace(0, 1, config.time_idependent_num_ts).to(device)\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(train_loader) * config.epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    min_val_loss = 1000\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            loss = train_batch_ode(x, y, t, model, optimizer, criterion, config)\n",
    "            example_ct +=  len(x)\n",
    "            batch_ct += 1\n",
    "\n",
    "            # Report metrics every 25th batch\n",
    "            if ((batch_ct + 1) % 100) == 0:\n",
    "                print(f'logging: {epoch=}, {loss=}, {example_ct=}')\n",
    "                wandb.log({\"epoch\": epoch, \"train_mse\": loss}, step=example_ct)\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                val_loss = test_log_vis(model,\n",
    "                                         t,\n",
    "                                           test_loader,\n",
    "                                            train_loader,\n",
    "                                             epoch,\n",
    "                                               example_ct,\n",
    "                                                min_val_loss,\n",
    "                                                full_X, full_y,\n",
    "                                                  config)\n",
    "                if val_loss < min_val_loss:\n",
    "                    min_val_loss = val_loss         \n",
    "\n",
    "def train_batch_ode(x, y, t, model, optimizer, criterion, config):\n",
    "    # print('HUI')  \n",
    "    # print(optimizer)  \n",
    "    optimizer.zero_grad()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "        \n",
    "    # Forward pass ➡\n",
    "    pred_y = odeint(model, y0=x, t=t, method=config.solver_type, adjoint_method=config.solver_type).to(device)\n",
    "    if not config.return_whole_sequence:\n",
    "        pred_y=pred_y[-1]\n",
    "        \n",
    "    loss = criterion(pred_y, y)\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test_log_vis(model, t, test_loader, train_loader, epoch, example_ct, min_val_loss, full_X, full_y, config):\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0 \n",
    "\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        t.to(device)\n",
    "        for _, (x, y) in enumerate(test_loader): \n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            pred_y = odeint(model, t=t, y0=x, method=config.solver_type, adjoint_method=config.solver_type).to(device)\n",
    "            if not config.return_whole_sequence:\n",
    "                pred_y=pred_y[-1]\n",
    "            loss = criterion(pred_y, y)\n",
    "            val_loss+=loss\n",
    "\n",
    "            X_test.append(x)\n",
    "            y_test.append(y)\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        val_loss = val_loss.item()    \n",
    "\n",
    "        wandb.log({\"epoch\": epoch, \"test_mse\": val_loss}, step=example_ct) \n",
    "        # visualising:\n",
    "        if val_loss < min_val_loss: \n",
    "            \"\"\" X_train y_train X_test y_test X_full, y_full\"\"\"\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            for x, y in train_loader:\n",
    "                X_train.append(x)\n",
    "                y_train.append(y)\n",
    "            X_train = torch.cat(X_train, dim=0)\n",
    "            X_test = torch.cat(X_test, dim=0)\n",
    "            y_train = torch.cat(y_train, dim=0)\n",
    "            y_test = torch.cat(y_test, dim=0)\n",
    "            full_X = torch.Tensor(full_X).to(device)\n",
    "\n",
    "\n",
    "\n",
    "            z_full = odeint(model, t=t.to(device), y0=full_X.to(device), method=config.solver_type, adjoint_method=config.solver_type).to(device)\n",
    "            if not config.return_whole_sequence:\n",
    "                z_full=z_full[-1].cpu()\n",
    "            full_X=full_X.cpu()\n",
    "            X_train=X_train.cpu()\n",
    "            X_test=X_test.cpu()\n",
    "            y_train = y_train.cpu()\n",
    "            y_test = y_test.cpu()\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(10, 7), dpi=100)\n",
    "            sc_1 = plt.scatter(X_train[:, 0], y_train[:, 0], color = 'black', s=5, label = 'Тренировочные данные')\n",
    "            plt.scatter(X_train[:, 0], y_train[:, 1], color = 'black', s=5)\n",
    "            sc_2 = plt.scatter(X_test[:, 0], y_test[:, 0], color = 'red', s=5, label = 'Тестовые данные')\n",
    "            plt.scatter(X_test[:, 0], y_test[:, 1], color = 'red', s=5)\n",
    "            plt.plot(full_X[:, 0], z_full[:, 0], color = 'green', label = 'Аппроксимация')\n",
    "            plt.plot(full_X[:, 0], z_full[:, 1], color = 'green')\n",
    "            \n",
    "            t = np.linspace(-3*np.pi/4, np.pi/4, 100, endpoint = True)\n",
    "            plt.plot(t, np.sin(t), color = 'pink', label = 'Незашумленные данные')\n",
    "            plt.plot(t, np.cos(t), color = 'pink')\n",
    "            plt.legend()\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.title('Результат ') \n",
    "        \n",
    "            wandb.log({\"Result\": wandb.Image(plt), 'epoch': epoch}, step=example_ct)\n",
    "        return val_loss               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_type': {'value': 'hyst_saved'},\n",
       " 'optimizer': {'value': 'adam'},\n",
       " 'arch_in_dim': {'value': 2},\n",
       " 'arch_hid_dim': {'values': [2, 4, 8, 16]},\n",
       " 'epochs': {'values': [1000, 3000, 10000]},\n",
       " 'batch_size': {'values': [16, 32, 64, 128]},\n",
       " 'learning_rate': {'value': 0.01},\n",
       " 'solver_type': {'values': ['euler', 'rk4', 'dopri5', 'bosh3']},\n",
       " 'time_idependent_num_ts': {'values': [2, 5, 10, 50]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "        trainloader, testloader, full_X, full_y, no_noise_y = build_dataset('hyst_saved', batch_size = 32)\n",
    "        network = build_network(2, 4)\n",
    "        optimizer = build_optimizer(network, 'adam', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0,1, 5).to(device)\n",
    "x, y = next(iter(trainloader))\n",
    "x, y =x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "        \n",
    "    # Forward pass ➡\n",
    "    pred_y = odeint(network, x, t=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = odeint(network, y0=full_X.to(device), t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.TensorDataset at 0x1eba9210eb0>,\n",
       " <torch.utils.data.dataset.TensorDataset at 0x1eba9210730>,\n",
       " tensor([[-2.3562,  1.0000],\n",
       "         [-2.3245,  1.0000],\n",
       "         [-2.2927,  1.0000],\n",
       "         [-2.2610,  1.0000],\n",
       "         [-2.2293,  1.0000],\n",
       "         [-2.1975,  1.0000],\n",
       "         [-2.1658,  1.0000],\n",
       "         [-2.1341,  1.0000],\n",
       "         [-2.1023,  1.0000],\n",
       "         [-2.0706,  1.0000],\n",
       "         [-2.0389,  1.0000],\n",
       "         [-2.0071,  1.0000],\n",
       "         [-1.9754,  1.0000],\n",
       "         [-1.9437,  1.0000],\n",
       "         [-1.9119,  1.0000],\n",
       "         [-1.8802,  1.0000],\n",
       "         [-1.8485,  1.0000],\n",
       "         [-1.8167,  1.0000],\n",
       "         [-1.7850,  1.0000],\n",
       "         [-1.7533,  1.0000],\n",
       "         [-1.7215,  1.0000],\n",
       "         [-1.6898,  1.0000],\n",
       "         [-1.6581,  1.0000],\n",
       "         [-1.6263,  1.0000],\n",
       "         [-1.5946,  1.0000],\n",
       "         [-1.5629,  1.0000],\n",
       "         [-1.5311,  1.0000],\n",
       "         [-1.4994,  1.0000],\n",
       "         [-1.4677,  1.0000],\n",
       "         [-1.4359,  1.0000],\n",
       "         [-1.4042,  1.0000],\n",
       "         [-1.3725,  1.0000],\n",
       "         [-1.3407,  1.0000],\n",
       "         [-1.3090,  1.0000],\n",
       "         [-1.2773,  1.0000],\n",
       "         [-1.2455,  1.0000],\n",
       "         [-1.2138,  1.0000],\n",
       "         [-1.1821,  1.0000],\n",
       "         [-1.1503,  1.0000],\n",
       "         [-1.1186,  1.0000],\n",
       "         [-1.0869,  1.0000],\n",
       "         [-1.0551,  1.0000],\n",
       "         [-1.0234,  1.0000],\n",
       "         [-0.9917,  1.0000],\n",
       "         [-0.9599,  1.0000],\n",
       "         [-0.9282,  1.0000],\n",
       "         [-0.8965,  1.0000],\n",
       "         [-0.8647,  1.0000],\n",
       "         [-0.8330,  1.0000],\n",
       "         [-0.8013,  1.0000],\n",
       "         [-0.7695,  1.0000],\n",
       "         [-0.7378,  1.0000],\n",
       "         [-0.7061,  1.0000],\n",
       "         [-0.6743,  1.0000],\n",
       "         [-0.6426,  1.0000],\n",
       "         [-0.6109,  1.0000],\n",
       "         [-0.5791,  1.0000],\n",
       "         [-0.5474,  1.0000],\n",
       "         [-0.5157,  1.0000],\n",
       "         [-0.4839,  1.0000],\n",
       "         [-0.4522,  1.0000],\n",
       "         [-0.4205,  1.0000],\n",
       "         [-0.3887,  1.0000],\n",
       "         [-0.3570,  1.0000],\n",
       "         [-0.3253,  1.0000],\n",
       "         [-0.2935,  1.0000],\n",
       "         [-0.2618,  1.0000],\n",
       "         [-0.2301,  1.0000],\n",
       "         [-0.1983,  1.0000],\n",
       "         [-0.1666,  1.0000],\n",
       "         [-0.1349,  1.0000],\n",
       "         [-0.1031,  1.0000],\n",
       "         [-0.0714,  1.0000],\n",
       "         [-0.0397,  1.0000],\n",
       "         [-0.0079,  1.0000],\n",
       "         [ 0.0238,  1.0000],\n",
       "         [ 0.0555,  1.0000],\n",
       "         [ 0.0873,  1.0000],\n",
       "         [ 0.1190,  1.0000],\n",
       "         [ 0.1507,  1.0000],\n",
       "         [ 0.1825,  1.0000],\n",
       "         [ 0.2142,  1.0000],\n",
       "         [ 0.2459,  1.0000],\n",
       "         [ 0.2777,  1.0000],\n",
       "         [ 0.3094,  1.0000],\n",
       "         [ 0.3411,  1.0000],\n",
       "         [ 0.3729,  1.0000],\n",
       "         [ 0.4046,  1.0000],\n",
       "         [ 0.4363,  1.0000],\n",
       "         [ 0.4681,  1.0000],\n",
       "         [ 0.4998,  1.0000],\n",
       "         [ 0.5315,  1.0000],\n",
       "         [ 0.5633,  1.0000],\n",
       "         [ 0.5950,  1.0000],\n",
       "         [ 0.6267,  1.0000],\n",
       "         [ 0.6585,  1.0000],\n",
       "         [ 0.6902,  1.0000],\n",
       "         [ 0.7219,  1.0000],\n",
       "         [ 0.7537,  1.0000],\n",
       "         [ 0.7854,  1.0000]]),\n",
       " tensor([[-0.6951, -0.6951],\n",
       "         [-0.7575, -0.6768],\n",
       "         [-0.7808, -0.6587],\n",
       "         [-0.6920, -0.6359],\n",
       "         [-0.7952, -0.5843],\n",
       "         [-0.7797, -0.5603],\n",
       "         [-0.7656, -0.5259],\n",
       "         [-0.7857, -0.5840],\n",
       "         [-0.9459, -0.5148],\n",
       "         [-0.8990, -0.4796],\n",
       "         [-0.9773, -0.5539],\n",
       "         [-0.8945, -0.4157],\n",
       "         [-0.9320, -0.4247],\n",
       "         [-0.9244, -0.3110],\n",
       "         [-0.8950, -0.3466],\n",
       "         [-0.8956, -0.3622],\n",
       "         [-0.9589, -0.2242],\n",
       "         [-0.9357, -0.2248],\n",
       "         [-1.0600, -0.1725],\n",
       "         [-0.9251, -0.2339],\n",
       "         [-0.9869, -0.1589],\n",
       "         [-0.9389, -0.1710],\n",
       "         [-0.9442, -0.0839],\n",
       "         [-0.9999, -0.0401],\n",
       "         [-1.0244, -0.0599],\n",
       "         [-0.9976,  0.0630],\n",
       "         [-0.9895,  0.0567],\n",
       "         [-1.0334,  0.1181],\n",
       "         [-0.9959,  0.1997],\n",
       "         [-1.0314,  0.1221],\n",
       "         [-1.0136,  0.2279],\n",
       "         [-0.9320,  0.1585],\n",
       "         [-0.9703,  0.2376],\n",
       "         [-1.0018,  0.2859],\n",
       "         [-0.9722,  0.3155],\n",
       "         [-0.9111,  0.2529],\n",
       "         [-0.9476,  0.3542],\n",
       "         [-0.8716,  0.3945],\n",
       "         [-0.8898,  0.3925],\n",
       "         [-0.8635,  0.4425],\n",
       "         [-0.8468,  0.4261],\n",
       "         [-0.8525,  0.4995],\n",
       "         [-0.8632,  0.5149],\n",
       "         [-0.8513,  0.5459],\n",
       "         [-0.8148,  0.5980],\n",
       "         [-0.7656,  0.6644],\n",
       "         [-0.7977,  0.6343],\n",
       "         [-0.8385,  0.6666],\n",
       "         [-0.7558,  0.7438],\n",
       "         [-0.6987,  0.7099],\n",
       "         [-0.7170,  0.6896],\n",
       "         [-0.6656,  0.7837],\n",
       "         [-0.6047,  0.7997],\n",
       "         [-0.6488,  0.8089],\n",
       "         [-0.5644,  0.8439],\n",
       "         [-0.5874,  0.7629],\n",
       "         [-0.5430,  0.7942],\n",
       "         [-0.5149,  0.8039],\n",
       "         [-0.4880,  0.8366],\n",
       "         [-0.4900,  0.8721],\n",
       "         [-0.4657,  0.9277],\n",
       "         [-0.4597,  0.9628],\n",
       "         [-0.4341,  0.9029],\n",
       "         [-0.3480,  0.9279],\n",
       "         [-0.3141,  0.9790],\n",
       "         [-0.2988,  1.0016],\n",
       "         [-0.2418,  0.9704],\n",
       "         [-0.1304,  1.0308],\n",
       "         [-0.2071,  0.9557],\n",
       "         [-0.1877,  0.9647],\n",
       "         [-0.1153,  0.9812],\n",
       "         [-0.0968,  1.0194],\n",
       "         [-0.0370,  1.0193],\n",
       "         [-0.0700,  0.9825],\n",
       "         [-0.0429,  0.9772],\n",
       "         [-0.0064,  0.9854],\n",
       "         [ 0.0775,  0.9112],\n",
       "         [ 0.1678,  0.9875],\n",
       "         [ 0.1522,  0.9618],\n",
       "         [ 0.0911,  0.9813],\n",
       "         [ 0.1413,  0.9338],\n",
       "         [ 0.2748,  1.0214],\n",
       "         [ 0.2024,  0.9346],\n",
       "         [ 0.2295,  0.9351],\n",
       "         [ 0.2613,  0.9917],\n",
       "         [ 0.3599,  0.9447],\n",
       "         [ 0.3793,  0.9107],\n",
       "         [ 0.3811,  0.8772],\n",
       "         [ 0.4451,  0.8600],\n",
       "         [ 0.4527,  0.8472],\n",
       "         [ 0.5419,  0.8843],\n",
       "         [ 0.5249,  0.8301],\n",
       "         [ 0.4709,  0.8004],\n",
       "         [ 0.5512,  0.8081],\n",
       "         [ 0.5432,  0.7402],\n",
       "         [ 0.6226,  0.7729],\n",
       "         [ 0.6468,  0.7718],\n",
       "         [ 0.5883,  0.6979],\n",
       "         [ 0.6586,  0.7079],\n",
       "         [ 0.7358,  0.7358]]),\n",
       " array([[-0.70710678, -0.70710678],\n",
       "        [-0.72918582, -0.68431575],\n",
       "        [-0.75053063, -0.66083566],\n",
       "        [-0.77111972, -0.63669017],\n",
       "        [-0.79093236, -0.61190359],\n",
       "        [-0.80994859, -0.58650088],\n",
       "        [-0.82814928, -0.5605076 ],\n",
       "        [-0.84551609, -0.53394995],\n",
       "        [-0.86203154, -0.50685465],\n",
       "        [-0.87767899, -0.47924899],\n",
       "        [-0.8924427 , -0.45116076],\n",
       "        [-0.90630779, -0.42261826],\n",
       "        [-0.9192603 , -0.39365022],\n",
       "        [-0.9312872 , -0.3642858 ],\n",
       "        [-0.94237637, -0.33455458],\n",
       "        [-0.95251665, -0.30448649],\n",
       "        [-0.96169783, -0.27411181],\n",
       "        [-0.96991066, -0.24346112],\n",
       "        [-0.97714687, -0.21256529],\n",
       "        [-0.98339917, -0.18145542],\n",
       "        [-0.98866128, -0.15016284],\n",
       "        [-0.99292788, -0.11871906],\n",
       "        [-0.9961947 , -0.08715574],\n",
       "        [-0.99845843, -0.05550466],\n",
       "        [-0.99971679, -0.0237977 ],\n",
       "        [-0.99996853,  0.00793323],\n",
       "        [-0.99921338,  0.03965617],\n",
       "        [-0.99745211,  0.07133918],\n",
       "        [-0.99468649,  0.10295036],\n",
       "        [-0.99091931,  0.13445788],\n",
       "        [-0.98615435,  0.16583001],\n",
       "        [-0.98039642,  0.19703516],\n",
       "        [-0.97365132,  0.22804191],\n",
       "        [-0.96592583,  0.25881905],\n",
       "        [-0.95722773,  0.28933557],\n",
       "        [-0.94756579,  0.31956076],\n",
       "        [-0.93694972,  0.34946418],\n",
       "        [-0.92539023,  0.37901572],\n",
       "        [-0.91289895,  0.40818562],\n",
       "        [-0.89948846,  0.43694451],\n",
       "        [-0.88517226,  0.46526344],\n",
       "        [-0.86996477,  0.49311389],\n",
       "        [-0.85388129,  0.52046781],\n",
       "        [-0.83693803,  0.54729766],\n",
       "        [-0.81915204,  0.57357644],\n",
       "        [-0.80054124,  0.59927767],\n",
       "        [-0.78112436,  0.62437547],\n",
       "        [-0.76092095,  0.64884459],\n",
       "        [-0.73995136,  0.67266037],\n",
       "        [-0.71823671,  0.69579885],\n",
       "        [-0.69579885,  0.71823671],\n",
       "        [-0.67266037,  0.73995136],\n",
       "        [-0.64884459,  0.76092095],\n",
       "        [-0.62437547,  0.78112436],\n",
       "        [-0.59927767,  0.80054124],\n",
       "        [-0.57357644,  0.81915204],\n",
       "        [-0.54729766,  0.83693803],\n",
       "        [-0.52046781,  0.85388129],\n",
       "        [-0.49311389,  0.86996477],\n",
       "        [-0.46526344,  0.88517226],\n",
       "        [-0.43694451,  0.89948846],\n",
       "        [-0.40818562,  0.91289895],\n",
       "        [-0.37901572,  0.92539023],\n",
       "        [-0.34946418,  0.93694972],\n",
       "        [-0.31956076,  0.94756579],\n",
       "        [-0.28933557,  0.95722773],\n",
       "        [-0.25881905,  0.96592583],\n",
       "        [-0.22804191,  0.97365132],\n",
       "        [-0.19703516,  0.98039642],\n",
       "        [-0.16583001,  0.98615435],\n",
       "        [-0.13445788,  0.99091931],\n",
       "        [-0.10295036,  0.99468649],\n",
       "        [-0.07133918,  0.99745211],\n",
       "        [-0.03965617,  0.99921338],\n",
       "        [-0.00793323,  0.99996853],\n",
       "        [ 0.0237977 ,  0.99971679],\n",
       "        [ 0.05550466,  0.99845843],\n",
       "        [ 0.08715574,  0.9961947 ],\n",
       "        [ 0.11871906,  0.99292788],\n",
       "        [ 0.15016284,  0.98866128],\n",
       "        [ 0.18145542,  0.98339917],\n",
       "        [ 0.21256529,  0.97714687],\n",
       "        [ 0.24346112,  0.96991066],\n",
       "        [ 0.27411181,  0.96169783],\n",
       "        [ 0.30448649,  0.95251665],\n",
       "        [ 0.33455458,  0.94237637],\n",
       "        [ 0.3642858 ,  0.9312872 ],\n",
       "        [ 0.39365022,  0.9192603 ],\n",
       "        [ 0.42261826,  0.90630779],\n",
       "        [ 0.45116076,  0.8924427 ],\n",
       "        [ 0.47924899,  0.87767899],\n",
       "        [ 0.50685465,  0.86203154],\n",
       "        [ 0.53394995,  0.84551609],\n",
       "        [ 0.5605076 ,  0.82814928],\n",
       "        [ 0.58650088,  0.80994859],\n",
       "        [ 0.61190359,  0.79093236],\n",
       "        [ 0.63669017,  0.77111972],\n",
       "        [ 0.66083566,  0.75053063],\n",
       "        [ 0.68431575,  0.72918582],\n",
       "        [ 0.70710678,  0.70710678]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_existing_hyst_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ii8ecgh5\n",
      "Sweep URL: https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tmjpmzlm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: euler\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_015910-tmjpmzlm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/tmjpmzlm' target=\"_blank\">prime-sweep-2</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/tmjpmzlm' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/tmjpmzlm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ccd9fdb65943e6a30ce6484e2642a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=49, loss=tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=3739\n",
      "logging: epoch=99, loss=tensor(0.0565, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7489\n",
      "logging: epoch=149, loss=tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=11239\n",
      "logging: epoch=199, loss=tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14989\n",
      "logging: epoch=249, loss=tensor(0.0101, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=18739\n",
      "logging: epoch=299, loss=tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22489\n",
      "logging: epoch=349, loss=tensor(0.0088, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=26239\n",
      "logging: epoch=399, loss=tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29989\n",
      "logging: epoch=449, loss=tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=33739\n",
      "logging: epoch=499, loss=tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37489\n",
      "logging: epoch=549, loss=tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=41239\n",
      "logging: epoch=599, loss=tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44989\n",
      "logging: epoch=649, loss=tensor(0.0091, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=48739\n",
      "logging: epoch=699, loss=tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52489\n",
      "logging: epoch=749, loss=tensor(32.0251, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=56239\n",
      "logging: epoch=799, loss=tensor(467.8259, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59989\n",
      "logging: epoch=849, loss=tensor(659.7383, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=63739\n",
      "logging: epoch=899, loss=tensor(895.9602, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67489\n",
      "logging: epoch=949, loss=tensor(1145.1941, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=71239\n",
      "logging: epoch=999, loss=tensor(1405.4500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c748d59f0214ec698cd0bc82ad01646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.188 MB of 0.204 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.922105…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁▁▁▁▁▁▁▄▅█</td></tr><tr><td>train_mse</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>test_mse</td><td>1456.41772</td></tr><tr><td>train_mse</td><td>1405.44995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-sweep-2</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/tmjpmzlm' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/tmjpmzlm</a><br/>Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_015910-tmjpmzlm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kbz551h6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: bosh3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_015942-kbz551h6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/kbz551h6' target=\"_blank\">sandy-sweep-3</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/kbz551h6' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/kbz551h6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56a7d6870eb4f19a1c005d5e7db7a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=98, loss=tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7425\n",
      "logging: epoch=198, loss=tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14925\n",
      "logging: epoch=298, loss=tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22425\n",
      "logging: epoch=398, loss=tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29925\n",
      "logging: epoch=498, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37425\n",
      "logging: epoch=598, loss=tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44925\n",
      "logging: epoch=698, loss=tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52425\n",
      "logging: epoch=798, loss=tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59925\n",
      "logging: epoch=898, loss=tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67425\n",
      "logging: epoch=998, loss=tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74925\n",
      "logging: epoch=1098, loss=tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=82425\n",
      "logging: epoch=1198, loss=tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=89925\n",
      "logging: epoch=1298, loss=tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=97425\n",
      "logging: epoch=1398, loss=tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=104925\n",
      "logging: epoch=1498, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=112425\n",
      "logging: epoch=1598, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=119925\n",
      "logging: epoch=1698, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=127425\n",
      "logging: epoch=1798, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=134925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter Chizhov\\AppData\\Local\\Temp\\ipykernel_21456\\4146877159.py:206: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 7), dpi=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=1898, loss=tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=142425\n",
      "logging: epoch=1998, loss=tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=149925\n",
      "logging: epoch=2098, loss=tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=157425\n",
      "logging: epoch=2198, loss=tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=164925\n",
      "logging: epoch=2298, loss=tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=172425\n",
      "logging: epoch=2398, loss=tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=179925\n",
      "logging: epoch=2498, loss=tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=187425\n",
      "logging: epoch=2598, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=194925\n",
      "logging: epoch=2698, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=202425\n",
      "logging: epoch=2798, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=209925\n",
      "logging: epoch=2898, loss=tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=217425\n",
      "logging: epoch=2998, loss=tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=224925\n",
      "logging: epoch=3098, loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=232425\n",
      "logging: epoch=3198, loss=tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=239925\n",
      "logging: epoch=3298, loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=247425\n",
      "logging: epoch=3398, loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=254925\n",
      "logging: epoch=3498, loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=262425\n",
      "logging: epoch=3598, loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=269925\n",
      "logging: epoch=3698, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=277425\n",
      "logging: epoch=3798, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=284925\n",
      "logging: epoch=3898, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=292425\n",
      "logging: epoch=3998, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=299925\n",
      "logging: epoch=4098, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=307425\n",
      "logging: epoch=4198, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=314925\n",
      "logging: epoch=4298, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=322425\n",
      "logging: epoch=4398, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=329925\n",
      "logging: epoch=4498, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=337425\n",
      "logging: epoch=4598, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=344925\n",
      "logging: epoch=4698, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=352425\n",
      "logging: epoch=4798, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=359925\n",
      "logging: epoch=4898, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=367425\n",
      "logging: epoch=4998, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=374925\n",
      "logging: epoch=5098, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=382425\n",
      "logging: epoch=5198, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=389925\n",
      "logging: epoch=5298, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=397425\n",
      "logging: epoch=5398, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=404925\n",
      "logging: epoch=5498, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=412425\n",
      "logging: epoch=5598, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=419925\n",
      "logging: epoch=5698, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=427425\n",
      "logging: epoch=5798, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=434925\n",
      "logging: epoch=5898, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=442425\n",
      "logging: epoch=5998, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=449925\n",
      "logging: epoch=6098, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=457425\n",
      "logging: epoch=6198, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=464925\n",
      "logging: epoch=6298, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=472425\n",
      "logging: epoch=6398, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=479925\n",
      "logging: epoch=6498, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=487425\n",
      "logging: epoch=6598, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=494925\n",
      "logging: epoch=6698, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=502425\n",
      "logging: epoch=6798, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=509925\n",
      "logging: epoch=6898, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=517425\n",
      "logging: epoch=6998, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=524925\n",
      "logging: epoch=7098, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=532425\n",
      "logging: epoch=7198, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=539925\n",
      "logging: epoch=7298, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=547425\n",
      "logging: epoch=7398, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=554925\n",
      "logging: epoch=7498, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=562425\n",
      "logging: epoch=7598, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=569925\n",
      "logging: epoch=7698, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=577425\n",
      "logging: epoch=7798, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=584925\n",
      "logging: epoch=7898, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=592425\n",
      "logging: epoch=7998, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=599925\n",
      "logging: epoch=8098, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=607425\n",
      "logging: epoch=8198, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=614925\n",
      "logging: epoch=8298, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=622425\n",
      "logging: epoch=8398, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=629925\n",
      "logging: epoch=8498, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=637425\n",
      "logging: epoch=8598, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=644925\n",
      "logging: epoch=8698, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=652425\n",
      "logging: epoch=8798, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=659925\n",
      "logging: epoch=8898, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=667425\n",
      "logging: epoch=8998, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=674925\n",
      "logging: epoch=9098, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=682425\n",
      "logging: epoch=9198, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=689925\n",
      "logging: epoch=9298, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=697425\n",
      "logging: epoch=9398, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=704925\n",
      "logging: epoch=9498, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=712425\n",
      "logging: epoch=9598, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=719925\n",
      "logging: epoch=9698, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=727425\n",
      "logging: epoch=9798, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=734925\n",
      "logging: epoch=9898, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=742425\n",
      "logging: epoch=9998, loss=tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=749925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>█▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>test_mse</td><td>0.00167</td></tr><tr><td>train_mse</td><td>0.00133</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-sweep-3</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/kbz551h6' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/kbz551h6</a><br/>Synced 5 W&B file(s), 65 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_015942-kbz551h6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xy7t4qjr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: euler\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 50\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_071145-xy7t4qjr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/xy7t4qjr' target=\"_blank\">jolly-sweep-4</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/xy7t4qjr' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/xy7t4qjr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497520d30056448ba964ce534cf402d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=98, loss=tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7425\n",
      "logging: epoch=198, loss=tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14925\n",
      "logging: epoch=298, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22425\n",
      "logging: epoch=398, loss=tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29925\n",
      "logging: epoch=498, loss=tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37425\n",
      "logging: epoch=598, loss=tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44925\n",
      "logging: epoch=698, loss=tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52425\n",
      "logging: epoch=798, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59925\n",
      "logging: epoch=898, loss=tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67425\n",
      "logging: epoch=998, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f68fd8fe4534e6f925333ef0c97f00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.637 MB of 0.637 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>test_mse</td><td>█▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>test_mse</td><td>0.00338</td></tr><tr><td>train_mse</td><td>0.00215</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-sweep-4</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/xy7t4qjr' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/xy7t4qjr</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_071145-xy7t4qjr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ffvvrn78 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: euler\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_071620-ffvvrn78</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ffvvrn78' target=\"_blank\">twilight-sweep-5</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ffvvrn78' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ffvvrn78</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f685129b97614b4a94fa32934293fbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=49, loss=tensor(0.0681, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=3739\n",
      "logging: epoch=99, loss=tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7489\n",
      "logging: epoch=149, loss=tensor(0.0110, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=11239\n",
      "logging: epoch=199, loss=tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14989\n",
      "logging: epoch=249, loss=tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=18739\n",
      "logging: epoch=299, loss=tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22489\n",
      "logging: epoch=349, loss=tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=26239\n",
      "logging: epoch=399, loss=tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29989\n",
      "logging: epoch=449, loss=tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=33739\n",
      "logging: epoch=499, loss=tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37489\n",
      "logging: epoch=549, loss=tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=41239\n",
      "logging: epoch=599, loss=tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44989\n",
      "logging: epoch=649, loss=tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=48739\n",
      "logging: epoch=699, loss=tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52489\n",
      "logging: epoch=749, loss=tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=56239\n",
      "logging: epoch=799, loss=tensor(169.7470, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59989\n",
      "logging: epoch=849, loss=tensor(420.1053, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=63739\n",
      "logging: epoch=899, loss=tensor(592.3427, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67489\n",
      "logging: epoch=949, loss=tensor(762.8329, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=71239\n",
      "logging: epoch=999, loss=tensor(943.5562, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74989\n",
      "logging: epoch=1049, loss=tensor(1133.8179, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=78739\n",
      "logging: epoch=1099, loss=tensor(1333.0728, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=82489\n",
      "logging: epoch=1149, loss=tensor(1540.9468, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=86239\n",
      "logging: epoch=1199, loss=tensor(1757.1545, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=89989\n",
      "logging: epoch=1249, loss=tensor(1981.4729, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=93739\n",
      "logging: epoch=1299, loss=tensor(2213.7271, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=97489\n",
      "logging: epoch=1349, loss=tensor(2453.8115, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=101239\n",
      "logging: epoch=1399, loss=tensor(2701.6519, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=104989\n",
      "logging: epoch=1449, loss=tensor(2957.2100, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=108739\n",
      "logging: epoch=1499, loss=tensor(3220.4583, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=112489\n",
      "logging: epoch=1549, loss=tensor(3491.4146, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=116239\n",
      "logging: epoch=1599, loss=tensor(3770.0962, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=119989\n",
      "logging: epoch=1649, loss=tensor(4056.5298, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=123739\n",
      "logging: epoch=1699, loss=tensor(4350.7651, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=127489\n",
      "logging: epoch=1749, loss=tensor(4651.9272, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=131239\n",
      "logging: epoch=1799, loss=tensor(4863.6260, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=134989\n",
      "logging: epoch=1849, loss=tensor(5204.2070, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=138739\n",
      "logging: epoch=1899, loss=tensor(5538.9756, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=142489\n",
      "logging: epoch=1949, loss=tensor(5853.6973, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=146239\n",
      "logging: epoch=1999, loss=tensor(6174.7485, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=149989\n",
      "logging: epoch=2049, loss=tensor(6502.2607, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=153739\n",
      "logging: epoch=2099, loss=tensor(6836.1641, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=157489\n",
      "logging: epoch=2149, loss=tensor(7176.3794, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=161239\n",
      "logging: epoch=2199, loss=tensor(7522.8555, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=164989\n",
      "logging: epoch=2249, loss=tensor(7875.5356, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=168739\n",
      "logging: epoch=2299, loss=tensor(8234.3730, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=172489\n",
      "logging: epoch=2349, loss=tensor(8599.3076, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=176239\n",
      "logging: epoch=2399, loss=tensor(8970.2891, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=179989\n",
      "logging: epoch=2449, loss=tensor(9347.2227, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=183739\n",
      "logging: epoch=2499, loss=tensor(9729.8574, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=187489\n",
      "logging: epoch=2549, loss=tensor(12042.6484, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=191239\n",
      "logging: epoch=2599, loss=tensor(14084.7773, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=194989\n",
      "logging: epoch=2649, loss=tensor(14689.9141, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=198739\n",
      "logging: epoch=2699, loss=tensor(15294.8047, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=202489\n",
      "logging: epoch=2749, loss=tensor(15900.6367, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=206239\n",
      "logging: epoch=2799, loss=tensor(16508.3477, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=209989\n",
      "logging: epoch=2849, loss=tensor(17118.6973, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=213739\n",
      "logging: epoch=2899, loss=tensor(17732.3125, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=217489\n",
      "logging: epoch=2949, loss=tensor(18349.7617, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=221239\n",
      "logging: epoch=2999, loss=tensor(18971.4863, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=224989\n",
      "logging: epoch=3049, loss=tensor(19597.8906, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=228739\n",
      "logging: epoch=3099, loss=tensor(20229.3047, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=232489\n",
      "logging: epoch=3149, loss=tensor(20866.0098, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=236239\n",
      "logging: epoch=3199, loss=tensor(21508.2656, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=239989\n",
      "logging: epoch=3249, loss=tensor(22156.2871, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=243739\n",
      "logging: epoch=3299, loss=tensor(22810.2695, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=247489\n",
      "logging: epoch=3349, loss=tensor(23470.3750, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=251239\n",
      "logging: epoch=3399, loss=tensor(24136.7500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=254989\n",
      "logging: epoch=3449, loss=tensor(24809.5176, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=258739\n",
      "logging: epoch=3499, loss=tensor(25488.7969, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=262489\n",
      "logging: epoch=3549, loss=tensor(26174.6855, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=266239\n",
      "logging: epoch=3599, loss=tensor(26867.2578, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=269989\n",
      "logging: epoch=3649, loss=tensor(27566.6211, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=273739\n",
      "logging: epoch=3699, loss=tensor(28272.8242, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=277489\n",
      "logging: epoch=3749, loss=tensor(28985.9219, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=281239\n",
      "logging: epoch=3799, loss=tensor(29705.9785, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=284989\n",
      "logging: epoch=3849, loss=tensor(30433.0332, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=288739\n",
      "logging: epoch=3899, loss=tensor(31167.1387, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=292489\n",
      "logging: epoch=3949, loss=tensor(31908.2969, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=296239\n",
      "logging: epoch=3999, loss=tensor(32656.5820, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=299989\n",
      "logging: epoch=4049, loss=tensor(33412.0156, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=303739\n",
      "logging: epoch=4099, loss=tensor(34174.6094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=307489\n",
      "logging: epoch=4149, loss=tensor(34944.3828, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=311239\n",
      "logging: epoch=4199, loss=tensor(35721.3711, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=314989\n",
      "logging: epoch=4249, loss=tensor(36505.5859, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=318739\n",
      "logging: epoch=4299, loss=tensor(37297.0312, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=322489\n",
      "logging: epoch=4349, loss=tensor(38095.7109, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=326239\n",
      "logging: epoch=4399, loss=tensor(38901.6797, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=329989\n",
      "logging: epoch=4449, loss=tensor(39714.9141, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=333739\n",
      "logging: epoch=4499, loss=tensor(40535.4297, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=337489\n",
      "logging: epoch=4549, loss=tensor(41363.2266, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=341239\n",
      "logging: epoch=4599, loss=tensor(42198.3203, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=344989\n",
      "logging: epoch=4649, loss=tensor(43040.7188, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=348739\n",
      "logging: epoch=4699, loss=tensor(43890.3906, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=352489\n",
      "logging: epoch=4749, loss=tensor(44747.3828, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=356239\n",
      "logging: epoch=4799, loss=tensor(45611.6914, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=359989\n",
      "logging: epoch=4849, loss=tensor(46483.2812, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=363739\n",
      "logging: epoch=4899, loss=tensor(47362.2266, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=367489\n",
      "logging: epoch=4949, loss=tensor(48248.4297, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=371239\n",
      "logging: epoch=4999, loss=tensor(49141.9961, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=374989\n",
      "logging: epoch=5049, loss=tensor(50042.8359, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=378739\n",
      "logging: epoch=5099, loss=tensor(50950.9844, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=382489\n",
      "logging: epoch=5149, loss=tensor(51866.4922, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=386239\n",
      "logging: epoch=5199, loss=tensor(52789.2617, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=389989\n",
      "logging: epoch=5249, loss=tensor(53719.3359, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=393739\n",
      "logging: epoch=5299, loss=tensor(54656.7070, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=397489\n",
      "logging: epoch=5349, loss=tensor(55601.4297, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=401239\n",
      "logging: epoch=5399, loss=tensor(56553.4141, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=404989\n",
      "logging: epoch=5449, loss=tensor(57512.7773, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=408739\n",
      "logging: epoch=5499, loss=tensor(58479.3438, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=412489\n",
      "logging: epoch=5549, loss=tensor(59453.3555, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=416239\n",
      "logging: epoch=5599, loss=tensor(60434.5234, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=419989\n",
      "logging: epoch=5649, loss=tensor(61423.0859, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=423739\n",
      "logging: epoch=5699, loss=tensor(62418.8438, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=427489\n",
      "logging: epoch=5749, loss=tensor(63421.9922, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=431239\n",
      "logging: epoch=5799, loss=tensor(64432.2734, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=434989\n",
      "logging: epoch=5849, loss=tensor(65450.0391, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=438739\n",
      "logging: epoch=5899, loss=tensor(66474.8281, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=442489\n",
      "logging: epoch=5949, loss=tensor(67507.1406, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=446239\n",
      "logging: epoch=5999, loss=tensor(68546.5156, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=449989\n",
      "logging: epoch=6049, loss=tensor(69593.2812, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=453739\n",
      "logging: epoch=6099, loss=tensor(70647.3438, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=457489\n",
      "logging: epoch=6149, loss=tensor(71708.5938, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=461239\n",
      "logging: epoch=6199, loss=tensor(72777.2500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=464989\n",
      "logging: epoch=6249, loss=tensor(73853., device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=468739\n",
      "logging: epoch=6299, loss=tensor(74936.2344, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=472489\n",
      "logging: epoch=6349, loss=tensor(76026.4375, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=476239\n",
      "logging: epoch=6399, loss=tensor(77123.9766, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=479989\n",
      "logging: epoch=6449, loss=tensor(78228.9688, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=483739\n",
      "logging: epoch=6499, loss=tensor(79340.9062, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=487489\n",
      "logging: epoch=6549, loss=tensor(80460.3750, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=491239\n",
      "logging: epoch=6599, loss=tensor(81586.9531, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=494989\n",
      "logging: epoch=6649, loss=tensor(82720.7188, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=498739\n",
      "logging: epoch=6699, loss=tensor(83861.9375, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=502489\n",
      "logging: epoch=6749, loss=tensor(85010.1562, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=506239\n",
      "logging: epoch=6799, loss=tensor(86165.5938, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=509989\n",
      "logging: epoch=6849, loss=tensor(87328.5547, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=513739\n",
      "logging: epoch=6899, loss=tensor(88498.4219, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=517489\n",
      "logging: epoch=6949, loss=tensor(89675.5625, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=521239\n",
      "logging: epoch=6999, loss=tensor(90860.2031, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=524989\n",
      "logging: epoch=7049, loss=tensor(92051.8125, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=528739\n",
      "logging: epoch=7099, loss=tensor(93250.5859, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=532489\n",
      "logging: epoch=7149, loss=tensor(94456.8516, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=536239\n",
      "logging: epoch=7199, loss=tensor(95670.1328, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=539989\n",
      "logging: epoch=7249, loss=tensor(96890.4375, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=543739\n",
      "logging: epoch=7299, loss=tensor(98118.3281, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=547489\n",
      "logging: epoch=7349, loss=tensor(99353.4297, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=551239\n",
      "logging: epoch=7399, loss=tensor(100595.3359, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=554989\n",
      "logging: epoch=7449, loss=tensor(101844.6797, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=558739\n",
      "logging: epoch=7499, loss=tensor(103101.4531, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=562489\n",
      "logging: epoch=7549, loss=tensor(104365.2031, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=566239\n",
      "logging: epoch=7599, loss=tensor(105635.8672, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=569989\n",
      "logging: epoch=7649, loss=tensor(106914.1406, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=573739\n",
      "logging: epoch=7699, loss=tensor(108199.7188, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=577489\n",
      "logging: epoch=7749, loss=tensor(109492.1406, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=581239\n",
      "logging: epoch=7799, loss=tensor(110791.6094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=584989\n",
      "logging: epoch=7849, loss=tensor(112098.6953, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=588739\n",
      "logging: epoch=7899, loss=tensor(113412.9922, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=592489\n",
      "logging: epoch=7949, loss=tensor(114734.1250, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=596239\n",
      "logging: epoch=7999, loss=tensor(116062.2969, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=599989\n",
      "logging: epoch=8049, loss=tensor(117398.1094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=603739\n",
      "logging: epoch=8099, loss=tensor(118741.1094, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=607489\n",
      "logging: epoch=8149, loss=tensor(120091.0781, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=611239\n",
      "logging: epoch=8199, loss=tensor(121447.8281, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=614989\n",
      "logging: epoch=8249, loss=tensor(122812.2734, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=618739\n",
      "logging: epoch=8299, loss=tensor(124183.9844, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=622489\n",
      "logging: epoch=8349, loss=tensor(125562.7500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=626239\n",
      "logging: epoch=8399, loss=tensor(126948.2109, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=629989\n",
      "logging: epoch=8449, loss=tensor(128341.1875, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=633739\n",
      "logging: epoch=8499, loss=tensor(129741.5781, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=637489\n",
      "logging: epoch=8549, loss=tensor(131149., device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=641239\n",
      "logging: epoch=8599, loss=tensor(132563.5000, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=644989\n",
      "logging: epoch=8649, loss=tensor(133984.6250, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=648739\n",
      "logging: epoch=8699, loss=tensor(135413.5312, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=652489\n",
      "logging: epoch=8749, loss=tensor(136849.6875, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=656239\n",
      "logging: epoch=8799, loss=tensor(138292.9375, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=659989\n",
      "logging: epoch=8849, loss=tensor(139743.1562, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=663739\n",
      "logging: epoch=8899, loss=tensor(141200., device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=667489\n",
      "logging: epoch=8949, loss=tensor(142664.6875, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=671239\n",
      "logging: epoch=8999, loss=tensor(144136.5625, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=674989\n",
      "logging: epoch=9049, loss=tensor(145615.4844, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=678739\n",
      "logging: epoch=9099, loss=tensor(147101.5312, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=682489\n",
      "logging: epoch=9149, loss=tensor(148594.1406, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=686239\n",
      "logging: epoch=9199, loss=tensor(150094.2500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=689989\n",
      "logging: epoch=9249, loss=tensor(151601.8906, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=693739\n",
      "logging: epoch=9299, loss=tensor(153116.5000, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=697489\n",
      "logging: epoch=9349, loss=tensor(154638.4688, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=701239\n",
      "logging: epoch=9399, loss=tensor(156167., device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=704989\n",
      "logging: epoch=9449, loss=tensor(157702.3750, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=708739\n",
      "logging: epoch=9499, loss=tensor(159245.5625, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=712489\n",
      "logging: epoch=9549, loss=tensor(160795.9844, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=716239\n",
      "logging: epoch=9599, loss=tensor(162353.2812, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=719989\n",
      "logging: epoch=9649, loss=tensor(163918.0469, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=723739\n",
      "logging: epoch=9699, loss=tensor(165489.2500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=727489\n",
      "logging: epoch=9749, loss=tensor(167067.3750, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=731239\n",
      "logging: epoch=9799, loss=tensor(168653.2500, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=734989\n",
      "logging: epoch=9849, loss=tensor(170246.4688, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=738739\n",
      "logging: epoch=9899, loss=tensor(171846.4688, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=742489\n",
      "logging: epoch=9949, loss=tensor(173453.9219, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=746239\n",
      "logging: epoch=9999, loss=tensor(175068.2188, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=749989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2266ad8b1e4ba297efde02c65c1e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.254 MB of 0.254 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>train_mse</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>test_mse</td><td>169775.875</td></tr><tr><td>train_mse</td><td>175068.21875</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-5</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ffvvrn78' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ffvvrn78</a><br/>Synced 5 W&B file(s), 4 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_071620-ffvvrn78\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0c3zdf5a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: rk4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 10\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_071944-0c3zdf5a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/0c3zdf5a' target=\"_blank\">dark-sweep-6</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/0c3zdf5a' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/0c3zdf5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643c7df78bf44aa5b8e5c692cff0d759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=19, loss=tensor(0.0445, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=1489\n",
      "logging: epoch=39, loss=tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=2989\n",
      "logging: epoch=59, loss=tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=4489\n",
      "logging: epoch=79, loss=tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=5989\n",
      "logging: epoch=99, loss=tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7489\n",
      "logging: epoch=119, loss=tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=8989\n",
      "logging: epoch=139, loss=tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=10489\n",
      "logging: epoch=159, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=11989\n",
      "logging: epoch=179, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=13489\n",
      "logging: epoch=199, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14989\n",
      "logging: epoch=219, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=16489\n",
      "logging: epoch=239, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=17989\n",
      "logging: epoch=259, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=19489\n",
      "logging: epoch=279, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=20989\n",
      "logging: epoch=299, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22489\n",
      "logging: epoch=319, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=23989\n",
      "logging: epoch=339, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=25489\n",
      "logging: epoch=359, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=26989\n",
      "logging: epoch=379, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=28489\n",
      "logging: epoch=399, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29989\n",
      "logging: epoch=419, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=31489\n",
      "logging: epoch=439, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=32989\n",
      "logging: epoch=459, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=34489\n",
      "logging: epoch=479, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=35989\n",
      "logging: epoch=499, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37489\n",
      "logging: epoch=519, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=38989\n",
      "logging: epoch=539, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=40489\n",
      "logging: epoch=559, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=41989\n",
      "logging: epoch=579, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=43489\n",
      "logging: epoch=599, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44989\n",
      "logging: epoch=619, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=46489\n",
      "logging: epoch=639, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=47989\n",
      "logging: epoch=659, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=49489\n",
      "logging: epoch=679, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=50989\n",
      "logging: epoch=699, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52489\n",
      "logging: epoch=719, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=53989\n",
      "logging: epoch=739, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=55489\n",
      "logging: epoch=759, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=56989\n",
      "logging: epoch=779, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=58489\n",
      "logging: epoch=799, loss=tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59989\n",
      "logging: epoch=819, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=61489\n",
      "logging: epoch=839, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=62989\n",
      "logging: epoch=859, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=64489\n",
      "logging: epoch=879, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=65989\n",
      "logging: epoch=899, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67489\n",
      "logging: epoch=919, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=68989\n",
      "logging: epoch=939, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=70489\n",
      "logging: epoch=959, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=71989\n",
      "logging: epoch=979, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=73489\n",
      "logging: epoch=999, loss=tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>█▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>test_mse</td><td>0.00214</td></tr><tr><td>train_mse</td><td>0.00191</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-6</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/0c3zdf5a' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/0c3zdf5a</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_071944-0c3zdf5a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ftocmemv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: euler\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 50\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_072712-ftocmemv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ftocmemv' target=\"_blank\">upbeat-sweep-7</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ftocmemv' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ftocmemv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9325064bce47438bbac3c41c98caf84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=98, loss=tensor(0.0564, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7425\n",
      "logging: epoch=198, loss=tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14925\n",
      "logging: epoch=298, loss=tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22425\n",
      "logging: epoch=398, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29925\n",
      "logging: epoch=498, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37425\n",
      "logging: epoch=598, loss=tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44925\n",
      "logging: epoch=698, loss=tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52425\n",
      "logging: epoch=798, loss=tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59925\n",
      "logging: epoch=898, loss=tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67425\n",
      "logging: epoch=998, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74925\n",
      "logging: epoch=1098, loss=tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=82425\n",
      "logging: epoch=1198, loss=tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=89925\n",
      "logging: epoch=1298, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=97425\n",
      "logging: epoch=1398, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=104925\n",
      "logging: epoch=1498, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=112425\n",
      "logging: epoch=1598, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=119925\n",
      "logging: epoch=1698, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=127425\n",
      "logging: epoch=1798, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=134925\n",
      "logging: epoch=1898, loss=tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=142425\n",
      "logging: epoch=1998, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=149925\n",
      "logging: epoch=2098, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=157425\n",
      "logging: epoch=2198, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=164925\n",
      "logging: epoch=2298, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=172425\n",
      "logging: epoch=2398, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=179925\n",
      "logging: epoch=2498, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=187425\n",
      "logging: epoch=2598, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=194925\n",
      "logging: epoch=2698, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=202425\n",
      "logging: epoch=2798, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=209925\n",
      "logging: epoch=2898, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=217425\n",
      "logging: epoch=2998, loss=tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=224925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106e533387a74043b2f337567fd6b72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.010 MB of 1.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.996849…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_mse</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2999</td></tr><tr><td>test_mse</td><td>0.00183</td></tr><tr><td>train_mse</td><td>0.00139</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-7</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ftocmemv' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ftocmemv</a><br/>Synced 5 W&B file(s), 16 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_072712-ftocmemv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ijuljgum with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: dopri5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_074048-ijuljgum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ijuljgum' target=\"_blank\">quiet-sweep-8</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ijuljgum' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ijuljgum</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce7663b6f246e2a63ae724f96587d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=19, loss=tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=1489\n",
      "logging: epoch=39, loss=tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=2989\n",
      "logging: epoch=59, loss=tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=4489\n",
      "logging: epoch=79, loss=tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=5989\n",
      "logging: epoch=99, loss=tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7489\n",
      "logging: epoch=119, loss=tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=8989\n",
      "logging: epoch=139, loss=tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=10489\n",
      "logging: epoch=159, loss=tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=11989\n",
      "logging: epoch=179, loss=tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=13489\n",
      "logging: epoch=199, loss=tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14989\n",
      "logging: epoch=219, loss=tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=16489\n",
      "logging: epoch=239, loss=tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=17989\n",
      "logging: epoch=259, loss=tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=19489\n",
      "logging: epoch=279, loss=tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=20989\n",
      "logging: epoch=299, loss=tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22489\n",
      "logging: epoch=319, loss=tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=23989\n",
      "logging: epoch=339, loss=tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=25489\n",
      "logging: epoch=359, loss=tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=26989\n",
      "logging: epoch=379, loss=tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=28489\n",
      "logging: epoch=399, loss=tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29989\n",
      "logging: epoch=419, loss=tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=31489\n",
      "logging: epoch=439, loss=tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=32989\n",
      "logging: epoch=459, loss=tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=34489\n",
      "logging: epoch=479, loss=tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=35989\n",
      "logging: epoch=499, loss=tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37489\n",
      "logging: epoch=519, loss=tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=38989\n",
      "logging: epoch=539, loss=tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=40489\n",
      "logging: epoch=559, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=41989\n",
      "logging: epoch=579, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=43489\n",
      "logging: epoch=599, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44989\n",
      "logging: epoch=619, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=46489\n",
      "logging: epoch=639, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=47989\n",
      "logging: epoch=659, loss=tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=49489\n",
      "logging: epoch=679, loss=tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=50989\n",
      "logging: epoch=699, loss=tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52489\n",
      "logging: epoch=719, loss=tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=53989\n",
      "logging: epoch=739, loss=tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=55489\n",
      "logging: epoch=759, loss=tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=56989\n",
      "logging: epoch=779, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=58489\n",
      "logging: epoch=799, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59989\n",
      "logging: epoch=819, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=61489\n",
      "logging: epoch=839, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=62989\n",
      "logging: epoch=859, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=64489\n",
      "logging: epoch=879, loss=tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=65989\n",
      "logging: epoch=899, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67489\n",
      "logging: epoch=919, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=68989\n",
      "logging: epoch=939, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=70489\n",
      "logging: epoch=959, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=71989\n",
      "logging: epoch=979, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=73489\n",
      "logging: epoch=999, loss=tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>█▇▆▄▂▂▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>test_mse</td><td>0.0024</td></tr><tr><td>train_mse</td><td>0.00207</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-8</strong> at: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ijuljgum' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/ijuljgum</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_074048-ijuljgum\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7220phsk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_hid_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch_in_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: hyst_saved\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treturn_whole_sequence: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver_type: bosh3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_idependent_num_ts: 10\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter Chizhov\\Desktop\\neuralODE\\project\\neuralODE\\wandb\\run-20230413_080512-7220phsk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/7220phsk' target=\"_blank\">misty-sweep-9</a></strong> to <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/sweeps/ii8ecgh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/7220phsk' target=\"_blank\">https://wandb.ai/peter_chizhov/pytorch-sweeps-demo/runs/7220phsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e822896ca54524a4ecb1fbd5926901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging: epoch=32, loss=tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=2475\n",
      "logging: epoch=66, loss=tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=4982\n",
      "logging: epoch=99, loss=tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=7489\n",
      "logging: epoch=132, loss=tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=9975\n",
      "logging: epoch=166, loss=tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=12482\n",
      "logging: epoch=199, loss=tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=14989\n",
      "logging: epoch=232, loss=tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=17475\n",
      "logging: epoch=266, loss=tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=19982\n",
      "logging: epoch=299, loss=tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=22489\n",
      "logging: epoch=332, loss=tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=24975\n",
      "logging: epoch=366, loss=tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=27482\n",
      "logging: epoch=399, loss=tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=29989\n",
      "logging: epoch=432, loss=tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=32475\n",
      "logging: epoch=466, loss=tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=34982\n",
      "logging: epoch=499, loss=tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=37489\n",
      "logging: epoch=532, loss=tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=39975\n",
      "logging: epoch=566, loss=tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=42482\n",
      "logging: epoch=599, loss=tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=44989\n",
      "logging: epoch=632, loss=tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=47475\n",
      "logging: epoch=666, loss=tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=49982\n",
      "logging: epoch=699, loss=tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=52489\n",
      "logging: epoch=732, loss=tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=54975\n",
      "logging: epoch=766, loss=tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=57482\n",
      "logging: epoch=799, loss=tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=59989\n",
      "logging: epoch=832, loss=tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=62475\n",
      "logging: epoch=866, loss=tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=64982\n",
      "logging: epoch=899, loss=tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=67489\n",
      "logging: epoch=932, loss=tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=69975\n",
      "logging: epoch=966, loss=tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=72482\n",
      "logging: epoch=999, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=74989\n",
      "logging: epoch=1032, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=77475\n",
      "logging: epoch=1066, loss=tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=79982\n",
      "logging: epoch=1099, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=82489\n",
      "logging: epoch=1132, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=84975\n",
      "logging: epoch=1166, loss=tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=87482\n",
      "logging: epoch=1199, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=89989\n",
      "logging: epoch=1232, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=92475\n",
      "logging: epoch=1266, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=94982\n",
      "logging: epoch=1299, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=97489\n",
      "logging: epoch=1332, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=99975\n",
      "logging: epoch=1366, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=102482\n",
      "logging: epoch=1399, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=104989\n",
      "logging: epoch=1432, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=107475\n",
      "logging: epoch=1466, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=109982\n",
      "logging: epoch=1499, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=112489\n",
      "logging: epoch=1532, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=114975\n",
      "logging: epoch=1566, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=117482\n",
      "logging: epoch=1599, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=119989\n",
      "logging: epoch=1632, loss=tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=122475\n",
      "logging: epoch=1666, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=124982\n",
      "logging: epoch=1699, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=127489\n",
      "logging: epoch=1732, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=129975\n",
      "logging: epoch=1766, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=132482\n",
      "logging: epoch=1799, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=134989\n",
      "logging: epoch=1832, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=137475\n",
      "logging: epoch=1866, loss=tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=139982\n",
      "logging: epoch=1899, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=142489\n",
      "logging: epoch=1932, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=144975\n",
      "logging: epoch=1966, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=147482\n",
      "logging: epoch=1999, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=149989\n",
      "logging: epoch=2032, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=152475\n",
      "logging: epoch=2066, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=154982\n",
      "logging: epoch=2099, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=157489\n",
      "logging: epoch=2132, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=159975\n",
      "logging: epoch=2166, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=162482\n",
      "logging: epoch=2199, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=164989\n",
      "logging: epoch=2232, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=167475\n",
      "logging: epoch=2266, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=169982\n",
      "logging: epoch=2299, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=172489\n",
      "logging: epoch=2332, loss=tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=174975\n",
      "logging: epoch=2366, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=177482\n",
      "logging: epoch=2399, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=179989\n",
      "logging: epoch=2432, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=182475\n",
      "logging: epoch=2466, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=184982\n",
      "logging: epoch=2499, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=187489\n",
      "logging: epoch=2532, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=189975\n",
      "logging: epoch=2566, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=192482\n",
      "logging: epoch=2599, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=194989\n",
      "logging: epoch=2632, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=197475\n",
      "logging: epoch=2666, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=199982\n",
      "logging: epoch=2699, loss=tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=202489\n",
      "logging: epoch=2732, loss=tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=204975\n",
      "logging: epoch=2766, loss=tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>), example_ct=207482\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE-ds-KE61R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
